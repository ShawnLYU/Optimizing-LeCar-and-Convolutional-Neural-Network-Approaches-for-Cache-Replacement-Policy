{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This note book is mainly about making predictions given the pre-trained models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import torch\n",
    "from torch import nn\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "CACHE_SIZE=100\n",
    "LR = 0.001  \n",
    "BATCH_SIZE=32\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Sequential(         \n",
    "            nn.Conv2d(\n",
    "                in_channels=1,              \n",
    "                out_channels=8,            \n",
    "                kernel_size=(30,3),         \n",
    "                stride=1,                   \n",
    "                padding=0,                  \n",
    "            ),                              \n",
    "            nn.ReLU(),                      \n",
    "        )\n",
    "        self.conv2 = nn.Sequential(         \n",
    "            nn.Conv2d(\n",
    "                in_channels=8,              \n",
    "                out_channels=16,            \n",
    "                kernel_size=(30,1),         \n",
    "                stride=1,                   \n",
    "                padding=2),    \n",
    "            nn.ReLU(),                      \n",
    "        )\n",
    "        self.out = nn.Sequential(\n",
    "            nn.Linear(3680,100),\n",
    "            )\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x.unsqueeze(1))\n",
    "        x = self.conv2(x)\n",
    "        x = x.view(x.size(0), -1)           # flatten the output of conv2 to (batch_size, 32 *#\n",
    "        output = self.out(x)\n",
    "        return output\n",
    "\n",
    "\n",
    "model = CNN()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Load the model and initiate the object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('cnn1/CNN.pth',map_location='cpu'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Necessary functions (mostly borrowed from Shabhaz with customization fitting for Conv NN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lruPredict(C,LRUQ,Y_OPT):\n",
    "    global lruCorrect, lruIncorrect\n",
    "    Y_current = []\n",
    "    KV = defaultdict(int)\n",
    "    for i in range(len(LRUQ)):\n",
    "        KV[LRUQ[i]] = len(LRUQ) - i\n",
    "    KV_sorted = Counter(KV)\n",
    "    evict_dict = dict(KV_sorted.most_common(eviction))\n",
    "    for e in C:\n",
    "        if e in evict_dict:\n",
    "            Y_current.append(1)\n",
    "        else:\n",
    "            Y_current.append(0)\n",
    "    for i in range(len(Y_current)):\n",
    "        if Y_current[i] is Y_OPT[i]:\n",
    "            lruCorrect+=1\n",
    "        else:\n",
    "            lruIncorrect+=1\n",
    "    return Y_current\n",
    "\n",
    "# returns sequence of blocks in prioirty order\n",
    "\n",
    "def Y_getBlockSeq(Y_pred_prob):\n",
    "    x = []\n",
    "    for i in range(len(Y_pred_prob)):\n",
    "        x.append(Y_pred_prob[i][0])\n",
    "    x = np.array(x)\n",
    "    idx = np.argsort(x)\n",
    "    idx = idx[:eviction]\n",
    "    return idx\n",
    "\n",
    "\n",
    "def Y_getMinPredict(Y_pred_prob):\n",
    "    x = []\n",
    "    for i in range(len(Y_pred_prob)):\n",
    "        x.append(Y_pred_prob[i][0])\n",
    "    x = np.array(x)\n",
    "    idx = np.argpartition(x, eviction)\n",
    "    \n",
    "    Y_pred = np.zeros(len(Y_pred_prob), dtype=int)\n",
    "    for i in range(eviction):\n",
    "        Y_pred[idx[i]] = 1\n",
    "    assert(Counter(Y_pred)[1] == eviction)\n",
    "    return Y_pred\n",
    "\n",
    "\n",
    "def lfuPredict(C,LFUDict,Y_OPT):\n",
    "    global lfuCorrect, lfuIncorrect\n",
    "    Y_current = []\n",
    "    KV = defaultdict()\n",
    "    for e in C:\n",
    "        KV[e] = LFUDict[e]\n",
    "    KV_sorted = Counter(KV)\n",
    "    evict_dict = dict(KV_sorted.most_common(eviction))\n",
    "    for e in C:\n",
    "        if e in evict_dict:\n",
    "            Y_current.append(1)\n",
    "        else:\n",
    "            Y_current.append(0)\n",
    "    for i in range(len(Y_current)):\n",
    "        if Y_current[i] is Y_OPT[i]:\n",
    "            lfuCorrect+=1\n",
    "        else:\n",
    "            lfuIncorrect+=1\n",
    "    return Y_current\n",
    "\n",
    "# return \"eviction\" blocks that are being accessed furthest\n",
    "# from the cache that was sent to us.\n",
    "\n",
    "def getY(C,D):\n",
    "    assert(len(C) == len(D))\n",
    "    Y_current = []\n",
    "    KV_sorted = Counter(D)\n",
    "    evict_dict = dict(KV_sorted.most_common(eviction))\n",
    "    assert(len(evict_dict) == eviction)\n",
    "    all_vals = evict_dict.values()\n",
    "    for e in C:\n",
    "        if e in evict_dict.values():\n",
    "            Y_current.append(1)\n",
    "        else:\n",
    "            Y_current.append(0)\n",
    "    #print (Y_current.count(1))\n",
    "    assert(Y_current.count(1) == eviction)\n",
    "    assert((set(all_vals)).issubset(set(C)))\n",
    "    return Y_current\n",
    "\n",
    "def getLFURow(LFUDict, C):\n",
    "    x_lfurow = []\n",
    "    for e in C:\n",
    "        x_lfurow.append(LFUDict[e])\n",
    "    norm = x_lfurow / np.linalg.norm(x_lfurow)\n",
    "    return norm\n",
    "    \n",
    "def getLRURow(LRUQ, C):\n",
    "    x_lrurow = []\n",
    "    KV = defaultdict(int)\n",
    "    for i in range(len(LRUQ)):\n",
    "        KV[LRUQ[i]] = i\n",
    "    for e in C:\n",
    "        x_lrurow.append(KV[e])\n",
    "    norm = x_lrurow / np.linalg.norm(x_lrurow)\n",
    "    return norm\n",
    "\n",
    "def normalize(feature, blocks):\n",
    "    x_feature = []\n",
    "    for i in range(len(blocks)):\n",
    "        x_feature.append(feature[blocks[i]])\n",
    "    return x_feature / np.linalg.norm(x_feature)\n",
    "\n",
    "def getX(LRUQ, LFUDict, C):\n",
    "#def getX(LRUQ, LFUDict, C, CacheTS, CachePID):   \n",
    "    X_lfurow = getLFURow(LFUDict, C)\n",
    "    X_lrurow = getLRURow(LRUQ, C)\n",
    "    X_bno    = C / np.linalg.norm(C)\n",
    "#     X_ts     = normalize(CacheTS, C)\n",
    "#     X_pid    = normalize(CachePID, C)\n",
    "    return (np.column_stack((X_lfurow, X_lrurow, X_bno)))\n",
    "    \n",
    "    \n",
    "def populateData(LFUDict, LRUQ, C, D):\n",
    "#def populateData(LFUDict, LRUQ, C, D, CacheTS, CachePID):\n",
    "    global X,Y\n",
    "    C = list(C)\n",
    "    Y_current = getY(C, D)\n",
    "    #X_current = getX(LRUQ, LFUDict, C, CacheTS, CachePID)\n",
    "    X_current = getX(LRUQ, LFUDict, C)\n",
    "    Y = np.append(Y, Y_current)\n",
    "    X = np.concatenate((X,X_current))\n",
    "    assert(Y_current.count(1) == eviction)\n",
    "    return Y_current\n",
    "\n",
    "\n",
    "def hitRate(blocktrace, frame, model):\n",
    "    LFUDict = defaultdict(int)\n",
    "    LRUQ = []\n",
    "#     CacheTS = defaultdict(int)\n",
    "#     CachePID = defaultdict(int)\n",
    "\n",
    "    hit, miss = 0, 0\n",
    "\n",
    "    C = []\n",
    "    evictCacheIndex = np.array([])\n",
    "    #count=0\n",
    "    #seq_number = 0\n",
    "    for seq_number, block in enumerate(tqdm(blocktrace, desc=\"OPT\")):\n",
    "        #print(len(evictCacheIndex))\n",
    "        LFUDict[block] +=1\n",
    "        #CacheTS[blocktrace[seq_number]] = timestamp[seq_number]\n",
    "        #CachePID[blocktrace[seq_number]] = pid[seq_number]\n",
    "        if block in C:\n",
    "            hit+=1\n",
    "#             if C.index(block) in evictCacheIndex:\n",
    "#                 np.delete(evictCacheIndex, C.index(block))\n",
    "                \n",
    "            LRUQ.remove(block)\n",
    "            LRUQ.append(block)\n",
    "        else:\n",
    "            evictPos = -1\n",
    "            miss+=1\n",
    "            if len(C) == frame:\n",
    "                if len(evictCacheIndex) == 0: # call eviction candidates\n",
    "                    #X_test = getX(LRUQ, LFUDict, C)\n",
    "                    #X_test = getX(LRUQ, LFUDict, C, CacheTS, CachePID)\n",
    "                    blockNo = C / np.linalg.norm(C)\n",
    "                    recency_ = np.array([LRUQ.index(i) for i in C])\n",
    "                    recency_ = recency_ / np.linalg.norm(recency_)\n",
    "                    frequency_ = np.array([LFUDict[i] for i in C])\n",
    "                    frequency_ = frequency_ / np.linalg.norm(frequency_)\n",
    "#                     stack = np.column_stack((blockNo, recency_, frequency_)).reshape(1,frame*3)\n",
    "                    stack = np.column_stack((blockNo, recency_, frequency_))\n",
    "                    #X_current = model.predict(stack)[0]\n",
    "                    evictCacheIndex = np.argsort(Y_pred_prob)[0].detach().numpy())[::-1][:eviction]\n",
    "                    # index of cache blocks that should be removed\n",
    "                    #return Y_pred_prob, evictCacheIndex\n",
    "                # evict from cache\n",
    "                evictPos = evictCacheIndex[0]\n",
    "                evictBlock = C[evictPos]\n",
    "                LRUQ.remove(evictBlock)\n",
    "                #del CacheTS [evictBlock]\n",
    "                #del CachePID [evictBlock]\n",
    "            if evictPos is -1:\n",
    "                C.append(block)\n",
    "            else:\n",
    "                C[evictPos] = block\n",
    "                evictCacheIndex = np.delete(evictCacheIndex, 0)\n",
    "            LRUQ.append(block)\n",
    "            #CacheTS [blocktrace[seq_number]] = timestamp[seq_number]\n",
    "            #CachePID [blocktrace[seq_number]] = pid[seq_number]\n",
    "        #seq_number += 1\n",
    "\n",
    "    hitrate = hit / (hit + miss)\n",
    "    print(hitrate)\n",
    "    return hitrate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load test data for predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook as tqdm \n",
    "from collections import Counter, deque, defaultdict\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "test = \"../../data/cheetah.cs.fiu.edu-110108-113008.4.blkparse\"\n",
    "\n",
    "df = pd.read_csv(test, sep=' ',header = None)\n",
    "df.columns = ['timestamp','pid','pname','blockNo', \\\n",
    "              'blockSize', 'readOrWrite', 'bdMajor', 'bdMinor', 'hash']\n",
    "\n",
    "testBlockTrace = df['blockNo'].tolist()\n",
    "testBlockTrace = testBlockTrace[:int(len(testBlockTrace)*0.1)]\n",
    "\n",
    "len(testBlockTrace)\n",
    "sampling_freq = CACHE_SIZE # number of samples skipped\n",
    "eviction = int(0.7 * CACHE_SIZE)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNNHitrate = hitRate(testBlockTrace, CACHE_SIZE, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
